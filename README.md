# ensemble-methods
*Experimentos de an√°lise comparativa entre m√©todos isolados e combinados*

## üîπ Vis√£o geral

Este reposit√≥rio re√∫ne tr√™s projetos/notebooks de machine learning que exploram distintos cen√°rios de predi√ß√£o, com foco especial em **ensemble methods**: comparar modelos cl√°ssicos (isolados) vs. combinar modelos via *voting* / *stacking*. O objetivo √©:  
- aplicar t√©cnicas supervised learning sem redes neurais profundas;  
- avaliar desempenho de modelos individuais;  
- comparar com ensemble (voting e stacking);  
- observar ganhos (ou n√£o) com a combina√ß√£o de modelos;  
- documentar boas pr√°ticas de ML (pr√©-processamento, tuning, valida√ß√£o, ensemble).

---

## üìÅ Estrutura do reposit√≥rio

| Arquivo / Notebook | Descri√ß√£o |
|------------------|-----------|
| `Facial_Recognition_with_Supervised_Learning.ipynb` | Experimento de reconhecimento facial (‚Äúpessoa X ou n√£o‚Äù) usando features PCA. Testa modelos cl√°ssicos + voting + stacking. |
| `ml_projeto_ensemble_class_good_book.ipynb` | Projeto gen√©rico de classifica√ß√£o (base ‚Äúbom livro/exemplo de livro did√°tico‚Äù) para comparar modelos cl√°ssicos e ensembles. |
| `predicting_movie_rental_durations.ipynb` | Regress√£o (ou regress√£o ‚Üí classifica√ß√£o/regi√£o?) de dura√ß√£o de loca√ß√£o de filmes ‚Äî explora predi√ß√£o de vari√°veis cont√≠nuas, possivelmente com ensembles (ou baseline de regress√£o). |
| `README.md` | Documenta√ß√£o principal |

---

## üß† M√©todos e t√©cnicas utilizados

Em diferentes notebooks, foram usados os seguintes m√©todos:

### ‚úÖ Modelos individuais / baselines  
- **LogisticRegression** ‚Äî regress√£o log√≠stica para classifica√ß√£o.  
- **SVC** (SVM) ‚Äî classifica√ß√£o com margem, usando kernel(s) configur√°veis.  
- **KNeighborsClassifier** (KNN) ‚Äî classifica√ß√£o baseada em similaridade/dist√¢ncia no espa√ßo de features.  
- Para problemas de regress√£o (quando aplic√°vel): regress√£o linear ou similar (dependendo do notebook).  

### üß© T√©cnicas de ensemble  
- **VotingClassifier** ‚Äî ensemble ‚Äúsoft voting‚Äù para classifica√ß√£o: combina probabilidades (ou scores) de m√∫ltiplos classificadores e decide pela classe com maior m√©dia.  
- **StackingClassifier** ‚Äî stacking (empilhamento): os modelos base geram predi√ß√µes que servem como features para um ‚Äúmeta-classificador‚Äù (no seu caso, geralmente LogisticRegression).  

### üîß Pr√©-processamento & tuning  
- Aplica√ß√£o de **PCA** para redu√ß√£o de dimensionalidade (especialmente no notebook de reconhecimento facial).  
- Uso de **RandomizedSearchCV** para ajustes de hiperpar√¢metros (C, kernel, n√∫mero de vizinhos, pesos, etc.).  
- Splits de treino/teste para valida√ß√£o da generaliza√ß√£o.  

---

## üìä O que foi testado / M√©tricas & Avalia√ß√£o  

Para cada experimento foram avaliadas ‚Äî quando cab√≠vel ‚Äî m√©tricas como:  
- F1-score (para classifica√ß√£o) ‚Äî via `f1_score`.  
- AUC / ROC (quando aplic√°vel).  
- Compara√ß√£o das performances dos modelos individuais vs. ensemble (voting / stacking).  

Al√©m disso, busca-se observar:  
- Se ensemble supera modelos individuais;  
- Em quais cen√°rios (tipo de dados / distribui√ß√£o / n√∫mero de features) ensembles trazem ganho ou n√£o;  
- E quais trade-offs aparecem (complexidade, risco de overfitting, custo computacional).  

---

## ‚úÖ O que foi aprendido / Conclus√µes parciais

- Ensembles via **VotingClassifier (soft voting)** tendem a dar ganhos consistentes quando os modelos base t√™m erros distintos (complementares).  
- **Stacking** ‚Äî quando implementado corretamente (com predi√ß√µes out-of-fold para meta) ‚Äî pode superar o voting, mas exige cuidado para evitar *data leakage*.  
- Pr√©-processamento e redu√ß√£o de dimensionalidade (como PCA) + tuning de hiperpar√¢metros s√£o fundamentais para extrair bom desempenho de modelos cl√°ssicos.  
- Modelos simples (LogisticRegression, SVM, KNN) ainda s√£o bastante √∫teis quando combinados, mesmo sem redes neurais / deep learning ‚Äî especialmente em dom√≠nios com features estruturadas ou extra√≠das via PCA.  
- Em problemas com muitos dados ou alta dimensionalidade, a combina√ß√£o de m√©todos e valida√ß√£o cuidadosa melhora estabilidade e generaliza√ß√£o.  

---

## üéØ Quando usar este reposit√≥rio / Para quem serve

Este reposit√≥rio √© √∫til para:  
- quem quer aprender e comparar **m√©todos cl√°ssicos de ML + ensembles**;  
- quem est√° em contextos onde **deep learning n√£o √© vi√°vel** ‚Äî por restri√ß√µes computacionais, de dados ou de interpretabilidade;  
- estudantes ou profissionais que querem ver **pr√°ticas de ML end-to-end**: pr√©-processamento, tuning, ensemble, avalia√ß√£o;  
- servir como base para adaptar para outros problemas (outros datasets de classifica√ß√£o / regress√£o).  

---

## üöÄ Como rodar / Pr√©-requisitos

1. Tenha instalado Python (vers√£o ‚â• 3.8) e bibliotecas usuals: `scikit-learn`, `pandas`, `numpy`, `matplotlib`, `seaborn` (se usar visualiza√ß√µes), etc.  
2. Clone este reposit√≥rio:  
   ```bash
   git clone https://github.com/analluvias/ensemble-methods.git  
   cd ensemble-methods  
